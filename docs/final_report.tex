\documentclass{article}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{url}
\usepackage{color}
% \usepackage{savetrees}
% \usepackage{listings}
% \usetikzlibrary{shapes}


\linespread{1.5}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1.9ex plus 0.5ex minus 0.2ex}

% \linespread{1.4}

\title{CSE613 Project\\Minute Sort -- Final Report}

\author{Dhruv Matani (108267786) \& Gaurav Menghani (108266803)}

\renewcommand{\thesubsection}{\thesection\ (\alph{subsection})}

\begin{document}
\maketitle

\clearpage

\section{Model}
We envisioned the model with two basic components:
\begin{enumerate}
\item {\bf{Intra-Node Sorting}}: We are using Merge-Sort with Parallel Merge on individual nodes. To do this in parallel, 
we are using Cilk++. 

\item {\bf{Inter-Node Sorting}}: For utilising multiple nodes, we will be using MPI. For distributing work evenly, 
we would be using the technique of oversampling.
\end{enumerate}

\section{Test Data \& Verification}
We are using \verb#gensort#\footnote{http://www.ordinal.com/gensort.html} for generating files with 100-byte records, 
of which the first 10 bytes is the key. gensort is used for the {\bf SortBenchmark\footnote{http://sortbenchmark.org/} contest}.

We use \verb#valsort# to verify that the data we have sorted is correct. Complying with the SortBenchmark contest data rules, we ensure that our results are comparable with others.

Prof. Chowdhury asked if we could verify that the sorted output data
is indeed a permutation of the input data, and not some other sorted
sequence. Note that such a sequence would be detected by
\verb#valsort# as a correctly sorted sequence!. To remedy this, we
wrote two programs:

\begin{enumerate}
\item \verb#populate#, which sets the first 8-bytes of the 90-byte
  non-key data in the records to have a unique value between $0$ and
  $nrecords-1$, and
\item \verb#verify#, which checks if the sorted records retain this
  property.
\end{enumerate}

The output produced by pur sorting routing passes the \verb#verify# test as well as the \verb#valsort# test.

\section{Summary of Work Done}
We have worked on the first component so far. We did the following:
\begin{enumerate}
\item We did some I/O benchmarking on Lonestar. Sequential read speed is \textit{96 MiB/s}. Sequential read + write speed is \textit{141 MiB/s}.
\item Did some Literature Survey to find that Triton Sort sorts 22.5 GB/s.
\item We then implemented Merge Sort and parallelised it using Cilk++.
\item We wrote a Parallel Merge routine, which finds the median of the merged array in $O(\log{n})$ time, and splits the arrays to be merged around the median. Finding the median, guarantees good load-balancing. Just performing a parallel merge based on the median results in no speedup. Even \textit{cilkview} reports \textit{1.01x} speedup on 2 through 16 processors. We don't yet know why this is the case.
\item We wrote tests to compare Parallel Merge using Median, with Serial Merge.
\item We also wrote an implementation of bottom-up iterative Merge Sort to find how fast it was in comparison to Top-Down Recursive Merge Sort \footnote{\url{https://gist.github.com/2369438} \& \url{https://gist.github.com/2369582}}.
\item If we use a different merging algorithm that uses only as much extra space as the smaller of the 2 sequences to be merged, then the running time is better than if we use the normal merging routing which copies each data item twice in the worst case.
\item Using the Parallel Merge with Parallel Merge Sort, we found out the running time of the algorithm on LoneStar. We found that sorting {\bf 2 GB} using this algorithm took about {\bf 15 seconds}.
\item We tested the algorithm on a private machine 
\footnote{Thanks to Anil Harwani for the access} (please refer 
to the Machine Specifications section for details).
	\begin{enumerate}
	\item To overlap I/O and computation, we used \texttt{mmap(2)} and \texttt{munmap(2)}.
	\item We observed that when the file being sorted was bigger than 3 GiB of size, there was
	an sudden drop in performance.
	\item After some investigation, we nailed this to the premature swapping out of the array.
	This was happening because in Linux and other kernels, the kernel does not allow more than
	a certain fraction of the pages in memory to be dirty, and periodically flushes out the
	pages.
	\item It turns out, we could tune both these parameters using tunables:
          \begin{enumerate}
          \item \verb#/proc/sys/vm/dirty_background_ratio# 
	  which defaults to \verb#10#, was set to \verb#90#.
	  \item \verb#/proc/sys/vm/dirty_ratio#
	  which defaults to \verb#20#, was set to \verb#90#.
	  \item \verb#/proc/sys/vm/dirty_expire_centisecs# 
	  which defaults to \verb#3000#, was set to \verb#8000#.
          \item \verb#/proc/sys/vm/dirty_writeback_centisecs# 
	  which defaults to \verb#1500#, was set to \verb#8000#.
          \end{enumerate}
          or simply by using the \verb#sysctl# command.
	\item We could then sort 10GiB in a minute.
	\end{enumerate}
\end{enumerate}

\section{Results}
We are able to sort 10GiB in a minute on a single machine.

We haven't added the Inter-Node Sorting module, because both Lonestar,
Ranger, \& Trestles had I/O bottlenecks which severly limited our
performance. Moreover, getting root access is not possible on these
clusters, which would have helped us tune the parameters for dirty
pages.


\section{Machine Specification}
The machine had the following configuration:
\begin{enumerate}
\item Dual Processor Opteron 6282SE (16 Core / 2.6 GHz / 16 MB L2 Cache / 16 MB L3 Cache)
\item 32 GB DDR3 1600 MHz Memory
\item Kingston HyperX SSD 120GB (advertized 555 MiB/s sequential read \& 510 MiB/s sequential write speed)
\end{enumerate}

\end{document}


